{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaffc8d0-25e6-45a4-9429-8b9adda2a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64819a6b-788b-4c15-a659-7cedae01adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f405e5a-a066-4553-bc89-44ff6c9d27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(question_body,question_title, tags):\n",
    "  import re\n",
    "  from keras.models import load_model\n",
    "  import tensorflow\n",
    "  import keras\n",
    "  import pickle as pkl\n",
    "  \n",
    "  stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "  from bs4 import BeautifulSoup\n",
    "  from tqdm import tqdm\n",
    "  preprocessed_questions_body = []\n",
    "  preprocessed_questions_title = []\n",
    "  preprocessed_tags = []\n",
    "\n",
    "  def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = ' '.join(e.lower() for e in phrase.split() if e.lower() not in stopwords)\n",
    "    # print(type(phrase))\n",
    "    # print(phrase)\n",
    "    return phrase\n",
    "  preprocessed_questions_body = decontracted(question_body)\n",
    "  preprocessed_questions_title= decontracted(question_title)\n",
    "  preprocessed_tags = decontracted(tags)\n",
    "\n",
    "\n",
    "  Complete = preprocessed_questions_body + \" \" + preprocessed_questions_title + \" \" + preprocessed_tags\n",
    "  # print(Complete)\n",
    "  with open('tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizeer=pkl.load(handle)\n",
    "    sequences_test = tokenizeer.texts_to_sequences([Complete])\n",
    "    \n",
    "    padded_text_test = pad_sequences(sequences_test, maxlen=200, padding='post')\n",
    "    print(padded_text_test.shape)\n",
    "\n",
    "  model = load_model('final_model.hdf5')\n",
    "  # f_names = model.feature_name\n",
    "  # model.feature_names = list(fg.industry.values)\n",
    "  # f_names = model.feature_names\n",
    "  # print(f_names)\n",
    "  predicted_industry=model.predict(padded_text_test)\n",
    "  # print(predicted_industry)\n",
    "\n",
    "  with open('vectorizer.pkl', 'rb') as handle:\n",
    "    vectorizer=pkl.load(handle)\n",
    "  feature_names = vectorizer.get_feature_names_out()\n",
    "  feature_names = pd.DataFrame(feature_names)\n",
    "\n",
    "  thresh = 0.01 #0.01\n",
    "  for dat in predicted_industry:\n",
    "    whr = np.where(dat > thresh)\n",
    "\n",
    "    # print(whr)\n",
    "  \n",
    "\n",
    "  predicted_class = feature_names.loc[whr]\n",
    "  print(\"Predicted classes are :\", predicted_class.values)\n",
    "\n",
    "\n",
    "  return predicted_class \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64cfcee5-0b1f-4643-a1de-f72a32875165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200)\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "Predicted classes are : [['computer_games']\n",
      " ['computer_networking']\n",
      " ['consumer_services']\n",
      " ['education_management']\n",
      " ['education_technology']\n",
      " ['finance_mortgage_underwriting']\n",
      " ['financial_services']\n",
      " ['financial_services_sales_technology']\n",
      " ['food_beverages']\n",
      " ['information_technology_services']\n",
      " ['law_practice']\n",
      " ['media_production']\n",
      " ['software']\n",
      " ['staffing_recruiting']\n",
      " ['technology']\n",
      " ['telecommunications']]\n"
     ]
    }
   ],
   "source": [
    "industry = function(question_body=\"i am student\",question_title=\"i am good in computer\", tags=\"eucational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b40051-2c49-465d-8566-ecb673388d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
